{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8.762523</td>\n",
       "      <td>6.646361</td>\n",
       "      <td>2.997420</td>\n",
       "      <td>4.014394</td>\n",
       "      <td>-10.413807</td>\n",
       "      <td>9.076811</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.994561</td>\n",
       "      <td>9.096160</td>\n",
       "      <td>6.954537</td>\n",
       "      <td>0.105904</td>\n",
       "      <td>-6.193367</td>\n",
       "      <td>-8.492825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.355991</td>\n",
       "      <td>7.499439</td>\n",
       "      <td>4.193364</td>\n",
       "      <td>2.829568</td>\n",
       "      <td>-6.665533</td>\n",
       "      <td>-8.125848</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.171629</td>\n",
       "      <td>-5.403025</td>\n",
       "      <td>2.834458</td>\n",
       "      <td>-6.508950</td>\n",
       "      <td>-4.454671</td>\n",
       "      <td>-1.297056</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-9.077276</td>\n",
       "      <td>6.415959</td>\n",
       "      <td>1.445529</td>\n",
       "      <td>4.916843</td>\n",
       "      <td>-9.087393</td>\n",
       "      <td>8.420642</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.575299</td>\n",
       "      <td>-3.749960</td>\n",
       "      <td>1.270082</td>\n",
       "      <td>-7.257834</td>\n",
       "      <td>-4.160710</td>\n",
       "      <td>-3.831128</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>6.616100</td>\n",
       "      <td>-6.296643</td>\n",
       "      <td>-7.076346</td>\n",
       "      <td>-6.225480</td>\n",
       "      <td>-4.170132</td>\n",
       "      <td>1.999122</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-1.962100</td>\n",
       "      <td>8.812093</td>\n",
       "      <td>4.422198</td>\n",
       "      <td>3.071947</td>\n",
       "      <td>-6.054211</td>\n",
       "      <td>-6.066600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-1.723541</td>\n",
       "      <td>-5.295087</td>\n",
       "      <td>0.942376</td>\n",
       "      <td>-6.049296</td>\n",
       "      <td>-4.624808</td>\n",
       "      <td>-2.326259</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-7.779903</td>\n",
       "      <td>5.564783</td>\n",
       "      <td>0.839042</td>\n",
       "      <td>2.122219</td>\n",
       "      <td>-9.857717</td>\n",
       "      <td>10.115739</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3         f4         f5  cluster\n",
       "0   -8.762523  6.646361  2.997420  4.014394 -10.413807   9.076811        1\n",
       "1   -2.994561  9.096160  6.954537  0.105904  -6.193367  -8.492825        0\n",
       "2   -3.355991  7.499439  4.193364  2.829568  -6.665533  -8.125848        0\n",
       "3   -0.171629 -5.403025  2.834458 -6.508950  -4.454671  -1.297056        3\n",
       "4   -9.077276  6.415959  1.445529  4.916843  -9.087393   8.420642        1\n",
       "..        ...       ...       ...       ...        ...        ...      ...\n",
       "195 -0.575299 -3.749960  1.270082 -7.257834  -4.160710  -3.831128        3\n",
       "196  6.616100 -6.296643 -7.076346 -6.225480  -4.170132   1.999122        2\n",
       "197 -1.962100  8.812093  4.422198  3.071947  -6.054211  -6.066600        0\n",
       "198 -1.723541 -5.295087  0.942376 -6.049296  -4.624808  -2.326259        3\n",
       "199 -7.779903  5.564783  0.839042  2.122219  -9.857717  10.115739        1\n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# producing clustering dataset\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "n_samples = 200\n",
    "n_features = 6\n",
    "n_clusters = 4\n",
    "# Generate random clustering dataset with 100 samples and 4 centers\n",
    "X, y = make_blobs(n_samples=n_samples, n_features=n_features , centers=n_clusters, random_state=42)\n",
    "\n",
    "\n",
    "df_x = pd.DataFrame(X)\n",
    "df_y = pd.DataFrame(y)\n",
    "df = pd.concat([df_x, df_y], axis=1)\n",
    "df.columns = ['f0', 'f1','f2','f3','f4','f5','cluster']\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of history\n",
    "history = {\n",
    "    'U': [],\n",
    "    'Z': [],\n",
    "    'W': [],\n",
    "    'cost': []\n",
    "\n",
    "    }\n",
    "time_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([140, 178,  95, 160])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initial centers randomly by choosing from hte dataset randomly\n",
    "Z_initial_index = np.random.choice(range(n_samples), size=n_clusters)\n",
    "Z_initial_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-8.199735</td>\n",
       "      <td>5.662003</td>\n",
       "      <td>1.956220</td>\n",
       "      <td>2.950435</td>\n",
       "      <td>-10.240146</td>\n",
       "      <td>9.445596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-3.348415</td>\n",
       "      <td>8.705074</td>\n",
       "      <td>4.971142</td>\n",
       "      <td>2.948715</td>\n",
       "      <td>-7.358801</td>\n",
       "      <td>-7.065769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-8.471730</td>\n",
       "      <td>6.383643</td>\n",
       "      <td>1.508433</td>\n",
       "      <td>3.102238</td>\n",
       "      <td>-9.650989</td>\n",
       "      <td>10.353339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-9.108203</td>\n",
       "      <td>6.344759</td>\n",
       "      <td>1.578007</td>\n",
       "      <td>4.538752</td>\n",
       "      <td>-8.831321</td>\n",
       "      <td>8.476032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           f0        f1        f2        f3         f4         f5\n",
       "140 -8.199735  5.662003  1.956220  2.950435 -10.240146   9.445596\n",
       "178 -3.348415  8.705074  4.971142  2.948715  -7.358801  -7.065769\n",
       "95  -8.471730  6.383643  1.508433  3.102238  -9.650989  10.353339\n",
       "160 -9.108203  6.344759  1.578007  4.538752  -8.831321   8.476032"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Centers of clusters of random samples of data, but they can be any random data_points not necessarily in dataset\n",
    "Z_df = df.iloc[Z_initial_index,:-1]\n",
    "Z_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.1997353 ,   5.66200285,   1.95622044,   2.95043536,\n",
       "        -10.24014622,   9.44559571],\n",
       "       [ -3.34841515,   8.70507375,   4.97114227,   2.94871481,\n",
       "         -7.35880143,  -7.06576857],\n",
       "       [ -8.47172951,   6.38364313,   1.50843332,   3.10223803,\n",
       "         -9.65098921,  10.35333936],\n",
       "       [ -9.10820269,   6.3447592 ,   1.57800697,   4.53875205,\n",
       "         -8.8313215 ,   8.47603172]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Z_df to ndarray\n",
    "Z = Z_df.to_numpy()\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['Z'].append(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.20792891, 0.09375181, 0.31333535, 0.03647016, 0.06505529,\n",
       "       0.28345848])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random weights that sum up to 1\n",
    "weights = np.random.dirichlet(np.ones(n_features), size=1).squeeze()\n",
    "weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['W'].append(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'U': [],\n",
       " 'Z': [array([[ -8.1997353 ,   5.66200285,   1.95622044,   2.95043536,\n",
       "          -10.24014622,   9.44559571],\n",
       "         [ -3.34841515,   8.70507375,   4.97114227,   2.94871481,\n",
       "           -7.35880143,  -7.06576857],\n",
       "         [ -8.47172951,   6.38364313,   1.50843332,   3.10223803,\n",
       "           -9.65098921,  10.35333936],\n",
       "         [ -9.10820269,   6.3447592 ,   1.57800697,   4.53875205,\n",
       "           -8.8313215 ,   8.47603172]])],\n",
       " 'W': [array([0.20792891, 0.09375181, 0.31333535, 0.03647016, 0.06505529,\n",
       "         0.28345848])],\n",
       " 'cost': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "• U is an M × k partition matrix, ui,l is a binary variable, and ui,l = 1 indicates that record i is allocated to cluster l.  \n",
    "• Z = {Z1, Z2, ..., Zk} is a set of k vectors representing the k-cluster centers.  \n",
    "• W = [w1, w2, ..., wN ] is a set of weights.  \n",
    "• d(xi,j, zl,j) is a distance or dissimilarity measure between object i and the center of cluster l on the jth feature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. P1: Fix Z and W ; solve the reduced problem for U\n",
    "2. P2: Fix U and W ; solve the reduced problem for Z\n",
    "3. P3: Fix U and Z ; solve the reduced problem for W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_distance(s1, s2, weight_vec, beta):\n",
    "    \"\"\"Calculate the weighted distance between two samples s1 and  s2 and based on the weights that each feature has\n",
    "\n",
    "    Args:\n",
    "        s1 (ndarray): _description_\n",
    "        s2 (ndarray): _description_\n",
    "        weight_vec (ndarray): a vector of size (n_features, ), each element is the weight of corresponding feature.\n",
    "        beta (scaler): the power of weights vector\n",
    "\n",
    "    Returns:\n",
    "        scaler: the weighted distance between two samples\n",
    "    \"\"\"\n",
    "    distance_vec = np.square(s1 - s2) # Element_wise --> for each feature\n",
    "    # w**beta\n",
    "    weights_beta_vector = np.power(weight_vec, beta)\n",
    "\n",
    "    weighted_distance = np.dot(distance_vec, weights_beta_vector.T)\n",
    "    return weighted_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1412066709406415"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_distance(Z[0],X[0], weights, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_center(sample, centers, weight_vector, beta=2):\n",
    "    \"\"\"it takes a sample and compare its distance to centers of clusters and return the cluster with closest center.\n",
    "\n",
    "    Args:\n",
    "        sample (ndarray): A vector that represent a data point\n",
    "        centers (ndarray): A ndarray with the shape of (n_clusters, n_features) where each row represent a center of a cluster\n",
    "        weight_vector (ndarray): a vector of wights for corresponding feature\n",
    "        beta (scaler): a bridge that bring\n",
    "    Returns:\n",
    "        int: the number of cluster which is closest to the samples\n",
    "    \"\"\"\n",
    "    d = [] # list of weighted distances\n",
    "    for c in centers:\n",
    "        w_d = weighted_distance(sample, c, weight_vector, beta)\n",
    "        d.append(w_d)\n",
    "    assigned_cluster = np.argmin(d)\n",
    "    return assigned_cluster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def u_calculation(data, centers, weights, beta = 2):\n",
    "   \"\"\" Calculate U based on Z and W and our dataset\n",
    "   \"\"\"\n",
    "   n_spl = data.shape[0] # umber of samples\n",
    "   n_clu = centers.shape[0] # number of clusters\n",
    "   u_matrix = np.zeros((n_spl, n_clu))\n",
    "   for i, x in enumerate(data):\n",
    "      l = closest_center(x, centers, weights, beta)\n",
    "      u_matrix[i][l] = 1\n",
    "   return u_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = u_calculation(X, Z, weights)\n",
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "history['U'].append(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_vec(U):\n",
    "    # a vector of size (n_samples, ) which each element shows the cluster that each samples is assigned to\n",
    "    c_vec = np.zeros(n_samples)\n",
    "    for m, u in enumerate(U):\n",
    "        c_vec[m] = np.argmax(u)\n",
    "    c_vec = c_vec.astype(int)\n",
    "    return c_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 3, 1, 3, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 0, 1, 3,\n",
       "       1, 2, 1, 1, 1, 0, 3, 3, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1,\n",
       "       1, 1, 0, 1, 3, 1, 2, 1, 1, 3, 3, 0, 3, 2, 3, 1, 3, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 0, 1, 0, 3, 1, 1, 1, 3, 1,\n",
       "       3, 1, 1, 3, 3, 1, 1, 2, 0, 1, 3, 1, 1, 1, 2, 3, 1, 1, 2, 1, 3, 3,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 0, 1, 3, 3, 1, 1, 1, 0, 1, 1, 3, 3,\n",
       "       3, 1, 3, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 3, 0, 1, 1,\n",
       "       0, 3, 1, 3, 3, 1, 3, 1, 1, 1, 1, 3, 0, 1, 1, 1, 1, 1, 3, 3, 1, 2,\n",
       "       3, 3, 1, 1, 2, 1, 1, 0, 3, 3, 1, 1, 1, 3, 1, 1, 3, 3, 1, 1, 3, 1,\n",
       "       1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_vec(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 18, 1: 121, 2: 13, 3: 48}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_elements, counts = np.unique(clusters_vec(U), return_counts=True)\n",
    "dict(zip(unique_elements, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(U, Z, W, X, beta = 2):\n",
    "    \"\"\"Calculate the cost function\n",
    "\n",
    "    Args:\n",
    "        U (ndarray):  U is an (M, k) matrix, ui,l is a binary variable, and ui,l = 1 indicates that record i is allocated to cluster l.\n",
    "        Z (ndarray): is a set of k vectors representing the k-cluster centers of size (n_clusters, n_features)\n",
    "        W (ndarray): W = [w1, w2, ..., wN ] is a set of weights of size (n_features, )\n",
    "        X (ndarray): matrix of records (n_records, n_features)\n",
    "        beta (int, optional): The power of elements of weights vector Defaults to 2.\n",
    "    \"\"\"\n",
    "    P = 0 # initial value of cost\n",
    "\n",
    "    cl_vec = clusters_vec(U)\n",
    "    \n",
    "    # Updating P\n",
    "    for m, c in enumerate(cl_vec):\n",
    "        w_d = weighted_distance(X[m], Z[c], W, beta)\n",
    "        P += w_d\n",
    "        P =  P.item() # to convert it to a single scaler\n",
    "    return(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_t = cost_function(U, Z, weights, X, beta = 2)\n",
    "history['cost'].append(c_t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusters_dict(U):\n",
    "    # Finding the index of samples in each cluster\n",
    "    n_clusters = U.shape[1]\n",
    "    cluster_dict = {}\n",
    "    clu_vec = clusters_vec(U)\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        cluster_dict[i] = np.where(clu_vec == i)[0]\n",
    "        \n",
    "    return cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z_update = np.zeros_like(Z)\n",
    "# for i,ind in cluster_dict.items():\n",
    "#     Z_update[i] = np.mean(X[ind], axis=0)\n",
    "\n",
    "# Z = Z_update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Z(U, Z, X):\n",
    "    \"\"\"Update Z i.e. the centers of clusters, by taking mean of teh samples in each cluster\n",
    "    \"\"\"\n",
    "    cluster_dict = clusters_dict(U)\n",
    "\n",
    "    new_Z = np.zeros_like(Z)\n",
    "    for i,ind in cluster_dict.items():\n",
    "        new_Z[i] = np.mean(X[ind], axis=0)\n",
    "    \n",
    "    return new_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update Z\n",
    "Z = history['Z'][-1] # the last update of Z\n",
    "weights = history['W'][-1] # the last update of weights\n",
    "\n",
    "Z_t = update_Z(U, Z, X) # new update of Z\n",
    "history['Z'].append(Z_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update cost\n",
    "c_t = cost_function(U, Z_t, weights, X, beta = 2) \n",
    "history['cost'].append(c_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1357.123070684594, 633.2688388565273]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving P3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Iteration over all features to calculate Dj\n",
    "# U = history['U'][-1] # the lsat update of U\n",
    "# Z = history['Z'][-1] # the lsat update of Z\n",
    "# cluster_dict = clusters_dict(U)\n",
    "\n",
    "# D = []\n",
    "# for j in range(n_features):\n",
    "#     d_j = 0\n",
    "#     for l in range(n_clusters):\n",
    "#         inx_in_cluster = cluster_dict[l]\n",
    "#         # Distance for feature \"j\" in cluster \"l\"\n",
    "#         d_j_l =np.sum(np.square(X[inx_in_cluster][j]-Z[l][j]))\n",
    "#         d_j += d_j_l\n",
    "\n",
    "#     D.append(d_j)\n",
    "\n",
    "# D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dj(X, U, Z):\n",
    "    # Iteration over all features to calculate Dj for each feature\n",
    "    \n",
    "    cluster_dict = clusters_dict(U)\n",
    "    n_features = X.shape[1]\n",
    "    n_clusters = U.shape[1]\n",
    "    \n",
    "    D = []\n",
    "    for j in range(n_features):\n",
    "        d_j = 0\n",
    "        for l in range(n_clusters):\n",
    "            inx_in_cluster = cluster_dict[l]\n",
    "            # Distance for feature \"j\" in cluster \"l\"\n",
    "            d_j_l =np.sum(np.square(X[inx_in_cluster][j]-Z[l][j]))\n",
    "            d_j += d_j_l\n",
    "\n",
    "        D.append(d_j)\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2401.4304522138245,\n",
       " 1619.4772747270167,\n",
       " 1083.13095666796,\n",
       " 1153.5709902598583,\n",
       " 2743.526073273181,\n",
       " 2356.3832383853282]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U = history['U'][-1] # the lsat update of U\n",
    "Z = history['Z'][-1] # the lsat update of Z\n",
    "d = dj(X, U, Z)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weights_update\n",
    "# weights_update = np.zeros_like(weights)\n",
    "# beta = 2\n",
    "\n",
    "# # wherever D is zero, the corresponding weight is zero\n",
    "# ind_D_zero = np.where(D == 0 )[0]\n",
    "# weights_update[ind_D_zero] = 0\n",
    "\n",
    "# ind_D_not_zero = np.where(D)[0]\n",
    "# for j in ind_D_not_zero:\n",
    "#     Dj_Dt = 0\n",
    "    \n",
    "#     for t in ind_D_not_zero:\n",
    "#        Dj_Dt += (D[j] / D[t]) ** (1 / ( beta - 1) )\n",
    "    \n",
    "#     weights_update[j] = 1 / Dj_Dt\n",
    "\n",
    "# weights_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_update(X, U, Z, weights, beta=2):\n",
    "\n",
    "    # D calculation:\n",
    "    D = dj(X, U, Z)\n",
    "\n",
    "    \n",
    "    # weights_update\n",
    "    weights_upd = np.zeros_like(weights)\n",
    "\n",
    "\n",
    "    # wherever D is zero, the corresponding weight is zero\n",
    "    ind_D_zero = np.where(D == 0 )[0] # indexes of zero Dj\n",
    "    weights_upd[ind_D_zero] = 0\n",
    "\n",
    "    # D is not zero\n",
    "    ind_D_not_zero = np.where(D)[0] ## indexes of non-zero Dj\n",
    "    for j in ind_D_not_zero:\n",
    "        \n",
    "        Dj_Dt = 0\n",
    "        for t in ind_D_not_zero:\n",
    "            Dj_Dt += (D[j] / D[t]) ** (1 / ( beta - 1) )\n",
    "        \n",
    "        weights_upd[j] = 1 / Dj_Dt\n",
    "\n",
    "    return weights_upd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c_t = cost_function(U, Z, weights_update, X, beta = 2)\n",
    "# c_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = history['U'][-1] # the lsat update of U\n",
    "Z = history['Z'][-1] # the lsat update of Z\n",
    "weights_t = weight_update(X, U, Z, weights, beta=2)\n",
    "history['W'].append(weights_t)\n",
    "c_t = cost_function(U, Z, weights_t, X, beta = 2)\n",
    "history['cost'].append(c_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1357.123070684594, 633.2688388565273, 701.9910928994457]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do it in a loop \n",
    "# keep track of changes for weights "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put everything together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final vector of weights is:\n",
      " [0.1221552  0.14781306 0.1861069  0.24110764 0.14648307 0.15633414] \n"
     ]
    }
   ],
   "source": [
    "cost_difference = []\n",
    "\n",
    "while True:\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "\n",
    "        # P1 --> update U\n",
    "        Z = history['Z'][-1] # the last update of Z\n",
    "        weights = history['W'][-1] # the last update of W\n",
    "        U = u_calculation(X, Z, weights)\n",
    "        history['U'].append(U)\n",
    "        U = history['U'][-1]\n",
    "        # update cost\n",
    "        c_t = cost_function(U, Z, weights, X, beta = 2)\n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    #P2 --> update Z\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "        U = history['U'][-1] # the last update of U\n",
    "        Z = history['Z'][-1] # the last update of Z\n",
    "        weights = history['W'][-1] # the last update of weights\n",
    "\n",
    "        Z_t = update_Z(U, Z, X) # new update of Z\n",
    "        history['Z'].append(Z_t)\n",
    "        # Update cost\n",
    "        c_t = cost_function(U, Z_t, weights, X, beta = 2) \n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    # P3 --> update  weights\n",
    "    cost_difference = np.abs(history['cost'][-1] - history['cost'][-2])\n",
    "    if  cost_difference > 0.0001:\n",
    "        U = history['U'][-1] # the lsat update of U\n",
    "        Z = history['Z'][-1] # the lsat update of Z\n",
    "        weights_t = weight_update(X, U, Z, weights, beta=2)\n",
    "        history['W'].append(weights_t)\n",
    "        #update cost\n",
    "        c_t = cost_function(U, Z, weights_t, X, beta = 2)\n",
    "        history['cost'].append(c_t)\n",
    "    else:\n",
    "        break\n",
    "\n",
    "final_weights = history['W'][-1]\n",
    "print(f'Final vector of weights is:\\n {final_weights} ')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1357.123070684594,\n",
       " 633.2688388565273,\n",
       " 701.9910928994457,\n",
       " 483.55057177647797,\n",
       " 281.0950928260165,\n",
       " 279.67408098944327,\n",
       " 225.9105896624502,\n",
       " 58.94471598521789,\n",
       " 57.33138500827003,\n",
       " 35.88445598240309,\n",
       " 34.5107177182021,\n",
       " 34.72282696450065,\n",
       " 34.72282696450065]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history['cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsupervised",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
